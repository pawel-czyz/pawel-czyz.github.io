{
  "hash": "1bcd791d9fd9871c23ede85a512037f1",
  "result": {
    "markdown": "---\ntitle: An almost binomial Markov chain\ndescription: Everybody knows how to toss a coin. This time we'll toss it a few times.\nauthor: Paweł Czyż\ndate: 1/19/2024\nexecute:\n  freeze: true\nformat:\n  html:\n    code-fold: true\n---\n\n## A Bernoulli random variable\n\nRecall that $Y\\sim \\mathrm{Bernoulli}(p)$ if $Y$ can attain values from the set $\\{0, 1\\}$ with probability $P(Y=1) = p$ and $P(Y=0) = 1-p$.\nIt's easy to see that:\n\n  - For every $k\\ge 1$ the random variables $Y^k$ and $Y$ are equal.\n  - The expected value is $\\mathbb E[Y] = p$.\n  - The variance is $\\mathbb{V}[Y]=\\mathbb E[Y^2]-\\mathbb E[Y]^2 = p-p^2 = p(1-p).$ From [AM-GM](https://en.wikipedia.org/wiki/AM%E2%80%93GM_inequality) we see that $\\mathbb{V}[Y] \\le (1/2)^2=1/4$.\n\nNow, if we consider independent and identically distributed variables $Y_1\\sim \\mathrm{Bernoulli}(p)$, $Y_2\\sim \\mathrm{Bernoulli}(p)$, ..., $Y_n\\sim \\mathrm{Bernoulli}(p)$, we can define a new variable\n$N_n = Y_1 + \\cdots + Y_n$\nand an average\n$$ \\bar Y^{(n)} = \\frac{N_n}{n}.$$\n\nThe random variable $N_n$ is distributed according to the binomial distribution and it's easy to calculate the mean $\\mathbb E[N_n] = np$ and variance $\\mathbb V[N_n] = np(1-p)$.\nConsequently,\n$\\mathbb E[ \\bar Y^{(n)} ] = p$ and $\\mathbb V[\\bar Y^{(n)}] = np(1-p)/n^2 = p(1-p)/n \\le 1/4n$. \n\nHence, we see that if we want to estimate $p$, then $\\bar Y^{(n)}$ is a reasonable estimator to use, and we can control its variance by choosing appropriate $n$.\n\nThinking about very large $n$, recall that the [strong law of large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers#Strong_law) guarantees that\n$$\nP\\left( \\lim\\limits_{n\\to \\infty} \\bar Y^{(n)} = p \\right) = 1.\n$$\n\n## A bit lazy coin tossing\nAbove we defined a sequence of independent Bernoulli variables. Let's introduce some dependency between them: define \n$$\nY_1\\sim \\mathrm{Bernoulli}(p)\n$$\nand, for $n\\ge 1$,\n$$\nY_{n+1}\\mid Y_n \\sim w\\,\\delta_{Y_n} +(1-w)\\, \\mathrm{Bernoulli}(p).\n$$\n\nHence, to draw $Y_1$ we simply toss a coin, but to draw $Y_2$ we can be lazy with probability $w$ and use the sampled value $Y_1$ or, with probability $1-w$, actually do the hard work of tossing a coin again.\n\nLet's think about the marginal distributions, i.e., we observe only the $n$th coin toss. As $Y_n$ takes values in $\\{0, 1\\}$, it has to be distributed according to *some* Bernoulli distribution.\n\nOf course, we have $\\mathbb E[Y_1] = p$, but what is $\\mathbb E[Y_2]$?\nUsing [the law of total expectation](https://en.wikipedia.org/wiki/Law_of_total_expectation) we have\n$$\n\\mathbb E[Y_2] = \\mathbb E[ \\mathbb E[Y_2\\mid Y_1] ] = \\mathbb E[ w Y_1 + (1-w)p ] = p.\n$$\nInteresting! Even if we have large $w$, e.g., $w=0.9$, we will still see $Y_2=1$ with original probability $p$.\nMore generally, we can prove by [induction](https://en.wikipedia.org/wiki/Mathematical_induction) that that $\\mathbb E[Y_n] = p$ for all $n\\ge 1$.\n\nTo calculate the variance, we could try [the law of total variance](https://en.wikipedia.org/wiki/Law_of_total_variance), but there is a simpler way: from the above observations we see that all the variables are distributed as $Y_n\\sim \\mathrm{Bernoulli}(p)$ (so they are identically distributed, but *not* independent for $w>0$) and the variance has to be $\\mathbb V[Y_n] = p(1-p)$.\n\nLet's now introduce variables $N_n = Y_1 + \\cdots + Y_n$ and $\\bar Y^{(n)}=N_n/n$.\nAs expectation is a linear operator, we know that\n$\\mathbb E[N_n] = np$ and $\\mathbb E[\\bar Y^{(n)}]=p$, but how *exactly* are these variables distributed? Or, at least, can we say anything about their variance?\n\nIt's instructive to see what happens for $w=1$: intuitively, we only tossed the coin once, and then just \"copied\" the result $n$ times, so that the sample size used to estimate $\\bar Y^{(n)}$ is still one.\n\nMore formally, with probability 1 we have $Y_1 = Y_2 = \\cdots = Y_n$, so that $N_n = nY_1$ and $\\mathbb V[N_n] = n^2p(1-p)$. Then, also with probability 1, we also have $\\bar Y^{(n)}=Y_1$ and $\\mathbb V[\\bar Y^{(n)}]=p(1-p)$. \n\nMore generally, we have\n$$\n\\mathbb V[N_n] = \\sum_{i=1}^n \\mathbb V[Y_i] + \\sum_{i\\neq j} \\mathrm{cov}[Y_i, Y_j]\n$$\nand we can suspect that the covariance terms will be non-negative, usually incurring larger variance than a corresponding binomial distribution (obtained from independent draws).\nLet's prove that.\n\n### Markov chain\nWe will be interested in covariance terms\n$$\\begin{align*}\n\\mathrm{cov}(Y_i, Y_{i+k}) &= \\mathbb E[Y_i\\cdot Y_{i+k}] - \\mathbb E[Y_i]\\cdot \\mathbb E[Y_{i+k}] \\\\\n&= P(Y_i=1, Y_{i+k}=1)-p^2 \\\\\n&= P(Y_i=1)P( Y_{i+k}=1\\mid Y_i=1) -p^2 \\\\\n&= p\\cdot P(Y_{i+k}=1 \\mid Y_i=1) - p^2.\n\\end{align*}\n$$\n\nTo calculate the probability $P(Y_{i+k}=1\\mid Y_i=1)$ we need an observation: the sampling procedure defines a Markov chain with the transition matrix\n$$\nT = \\begin{pmatrix}\n    P(0\\to 0) & P(0 \\to 1)\\\\\n    P(1\\to 0) & P(1\\to 1)\n\\end{pmatrix}\n= \\begin{pmatrix}\n    w+(1-w)(1-p) & p(1-w)\\\\\n    (1-w)(1-p) & w + p(1-w)\n\\end{pmatrix}.\n$$\n\nBy induction and a handy identity $(1-x)(1+x+\\cdots + x^{k-1}) = 1-x^{k}$ one can prove that\n$$\nT^k = \\begin{pmatrix}\n    1-p(1-w^k) & p(1-w^k)\\\\\n    (1-p)(1-w^k) & p+w^k(1-p),\n\\end{pmatrix}\n$$\nfrom which we can conveniently read\n$$\nP(Y_{i+k}=1\\mid Y_i=1) = p+w^k(1-p)\n$$\nand\n$$\\mathrm{cov}(Y_i, Y_{i+k}) = w^k\\cdot p(1-p).$$\n\nGreat, these terms are always non-negative! Let's do a quick check: for $w=0$ the covariance terms vanish, resulting in $\\mathbb V[N_n]=np(1-p) + 0$ and for $w=1$ we have $\\mathbb V[N_n] = np(1-p) + n(n-1)p(1-p)=n^2p(1-p)$.\n\nFor $w\\neq 1$ we can use the same identity as before to get \n$$\\begin{align*}\n    \\mathbb V[N_n] &= p(1-p)\\cdot \\left(n+\\sum_{i=1}^n \\sum_{k=1}^{n-i} w^k \\right) \\\\\n    &= p(1-p)\\left( n+ \\frac{2 w \\left(w^n-n w+n-1\\right)}{(w-1)^2} \\right)\n\\end{align*}\n$$\n\nLet's numerically check whether this formula seems right:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom functools import partial\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import random, lax\n\n@partial(jax.jit, static_argnames=[\"n\"])\ndef simulate_markov_chain(key, n: int, p: float, w: float) -> jnp.ndarray:\n    keys = random.split(key, n)\n\n    def step(i, y):\n        key_w, key_p = random.split(keys[i])\n        y_prev = y[i-1]\n        mixture_sample = random.bernoulli(key_w, w)\n        y_next = jnp.where(mixture_sample, y_prev, random.bernoulli(key_p, p))\n        y = y.at[i].set(y_next)\n        return y\n    \n    y_init = jnp.zeros(n, dtype=jnp.int32)\n    y_init = y_init.at[0].set(random.bernoulli(keys[0], p))\n\n    y_final = lax.fori_loop(1, n, step, y_init)\n    return y_final\n\ndef simulate_correlated_binomial(key, n: int, p: float, w: float) -> int: \n    return simulate_markov_chain(key=key, n=n, p=p, w=w).sum()\n\n@partial(jax.jit, static_argnames=[\"n\", \"n_samples\"])\ndef sample_correlated_binomial(key, n: int, p: float, w: float, n_samples: int = 1_000_000) -> jnp.ndarray:\n    keys = random.split(key, n_samples)\n    return jax.vmap(partial(simulate_correlated_binomial, n=n, p=p, w=w))(keys)\n\ndef variance_correlated_binomial(n: int, p: float, w: float) -> float:\n    factor = n**2\n    if w < 1.0:\n        factor = n + ( 2 * w * (-1 + n - n * w + w**n)) / (-1 + w)**2\n    return p*(1-p) * factor\n\nkey = random.PRNGKey(2024-1-19)\n\ntest_cases = [\n    (10, 0.5, 0.5),\n    (10, 0.3, 0.8),\n    (10, 0.2, 0.1),\n    (5, 0.4, 0.3),\n    (20, 0.8, 0.7),\n]\n\nfor n, p, w in test_cases:\n    key, subkey = random.split(key)\n    approx = jnp.var(sample_correlated_binomial(subkey, n, p, w))\n    exact = variance_correlated_binomial(n, p, w)\n\n    print(f\"Variance (appr.): {approx:.2f}\")\n    print(f\"Variance (exact): {exact:.2f}\")\n    print(\"-\"*23)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nAn NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nVariance (appr.): 6.50\nVariance (exact): 6.50\n-----------------------\nVariance (appr.): 11.40\nVariance (exact): 11.40\n-----------------------\nVariance (appr.): 1.92\nVariance (exact): 1.92\n-----------------------\nVariance (appr.): 1.93\nVariance (exact): 1.94\n-----------------------\nVariance (appr.): 15.66\nVariance (exact): 15.65\n-----------------------\n```\n:::\n:::\n\n\n## Markov chain Monte Carlo\n\nRecall that when the samples are independent, we can estimate $p$ via $\\bar Y^{(n)}$ which is an unbiased estimator, i.e., $\\mathbb E[\\bar Y^{(n)}] = p$ and its variance is $\\mathbb V[\\bar Y^{(n)}]=p(1-p)/n\\le 1/4n$.\n\nWhen we passed to a Markov chain introducing parameter $w$, we also found out that $\\mathbb E[\\bar Y^{(n)}]=p$. Moreover, for $w<1$ (i.e., there's some genuine sampling, rather than copying the first result) the variance of $N_n$ also grows as $\\mathcal O(n + w^n)=\\mathcal O(n)$, so that $\\mathbb V[\\bar Y^{(n)}] =\\mathcal O(1/n)$, so that for a large $n$ the estimator $\\bar Y^{(n)}$ can be a reliable estimator for $p$.\nHowever, note that in the variance there's a term $1/(1-w)^2$, so that for $w$ close to $1$ one may have to use very, very, very large $n$ to make sure that the variance is small enough.\n\nThis Markov chain is in fact connected to Markov chain Monte Carlo samplers, used to sample from a given distribution.\n\nThe Markov chain $Y_2, Y_3, \\dotsc$ has transition matrix $T$ and initial distribution of $Y_1$ (namely $\\mathrm{Bernoulli}(p)$). For $0 < p < 1$ and $w < 1$ the transition matrix has positive entries, which implies that this Markov chain is ergodic (both irreducibility and aperiodicity are trivially satisfied in this case; more generally [quasi-positivity](https://www.mathematik.uni-ulm.de/stochastik/lehre/ss06/markov/skript_engl/node10.html), i.e., $T^k$ has positive entries for some $k\\ge 1$, is [equivalent to ergodicity](https://www.mathematik.uni-ulm.de/stochastik/lehre/ss06/markov/skript_engl/node12.html)). \n\nWe can deduce two things. First, there's a unique stationary distribution of this Markov chain. \nIt can be found by solving the equations for the eigenvector $T^{t}\\pi=\\pi$; in this case $\\pi=(1-p, p)$ (what a surprise!), meaning that the stationary distribution is $\\mathrm{Bernoulli}(p)$.\n\nSecondly, we can use the [ergodic theorem](https://www.statslab.cam.ac.uk/~james/Markov/s110.pdf).\nThe ergodic theorem states that in this case for every function[^1] $f\\colon \\{0, 1\\}\\to \\mathbb R$ it holds that\n$$\nP\\left(\\lim\\limits_{n\\to\\infty} \\frac{1}{n}\\sum_{i=1}^n f(Y_i) = \\mathbb E[f] \\right) = 1\n$$\nwhere the expectation $\\mathbb E[f]$ is taken with respect to $\\pi$.\n\n[^1]: Usually one has to add that the function is bounded. But we are working with a finite domain $\\{0, 1\\}$, so literally every function is bounded.\n\nNote that for $f(x) = x$ we find out that with probability $1$ it holds that $\\lim\\limits_{n\\to \\infty} \\bar Y^{(n)} = p$.\n\nPerhaps it's worth commenting on why the stationary distribution is $\\mathrm{Bernoulli}(p)$. Consider any distribution $\\mathcal D$ and a Markov chain\n$$\nY_{n+1} \\mid Y_n \\sim w\\, \\delta_{Y_{n}} + (1-w)\\, \\mathcal D\n$$\nfor $w < 1$.\nIntuitively, this Markov chain will either jump to a new location with the right probability, or stay at a current point by some additional time. This additional time depends only on $w$, so that on average, at each point we spend the same time. Hence, it should not affect time averages over very, very, very long sequences.\n(However, as we have seen, large $w$ may imply large autocorrelation in the Markov chain and the chain would have to be extremely long to yield acceptable variance).\n\nI think it should not be hard to formalize and prove the above observation, but it's not for today. [This review](https://arxiv.org/abs/2110.07032) could be useful for investigating this further.\n\n\n## How does it differ from beta-binomial?\n\nRecall that a [beta-binomial distribution](https://en.wikipedia.org/wiki/Beta-binomial_distribution) generates samples as follows:\n\n1. Draw $b\\sim \\mathrm{Beta}(\\alpha, \\beta)$;\n2. Then, draw $M \\mid b \\sim \\mathrm{Binomial}(n, b)$.\n\nHence, first a random coin is selected from a set of coins with different biases, and then it's tossed $n$ times. This distribution has two degrees of freedom: $\\alpha$ and $\\beta$, and allows one a more flexible control over both the mean and the variance. The mean is given by\n$$\n\\mathbb E[M] = n\\frac{\\alpha}{\\alpha + \\beta},\n$$\nso if we write $p = \\alpha/(\\alpha + \\beta)$, we match the mean of a \"corresponding\" binomial distribution.\nThe variance is given by\n$$\n\\mathbb V[M] = np(1-p)\\left(1 + \\frac{n-1}{\\alpha + \\beta + 1} \\right),\n$$\nso that for $n \\ge 2$ we will see a larger variance than for a binomial distribution with corresponding mean. \n\nWe see that this variance is quadratic in $n$, which is different from the formula for the variance of the almost binomial Markov chain.\nNevertheless, we can ask ourselves a question whether beta-binomial can be a good approximation to the distribution studied before.\n\nThis intuition may be formalized in many ways, e.g., as minimization of statistical discrepancy measures, including total variation, various Wasserstain distances or $f$-divergences.\nInstead, we will just match mean and variance.\n\nSo, of course, we will take $p=\\alpha/(\\alpha + \\beta)$ and additionally solve for\n$\\mathbb V[M] = V$.\nThe solution is then given by\n$$\\begin{align*}\n\\alpha &= pR,\\\\\n\\beta &= (1-p)R,\\\\\nR &= \\frac{n^2 p(1-p)-V}{V - n p(1-p)}.\n\\end{align*}\n$$\n\nNow it's coding time! We could use [TensorFlow Probability on JAX to sample from beta-binomial distribution](https://github.com/google/jax/issues/13327), but we will resort to core JAX.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt \nplt.style.use(\"dark_background\")\n\ndef find_alpha_beta(n: int, p: float, variance: float) -> tuple[float, float]:\n    num = n**2 * p * (1-p) - variance\n    den = variance - n * p * (1-p)\n    r = num / den\n\n    if r <= 0 or p <= 0 or p >= 1:\n        raise ValueError(\"Input results in non-positive alpha or beta\")\n\n    return p*r, (1-p) * r\n\n@partial(jax.jit, static_argnames=[\"n\"])\ndef _sample_beta_binomial(key, n: int, alpha: float, beta: float) -> int:\n    key_p, key_b = random.split(key)\n    p = random.beta(key_p, a=alpha, b=beta)\n    ber = random.bernoulli(key_b, p=p, shape=(n,))\n    return jnp.sum(ber)\n\n@partial(jax.jit, static_argnames=[\"n\", \"n_samples\"])\ndef sample_beta_binomial(key, n: int, alpha: float, beta: float, n_samples: int = 1_000_000) -> jnp.ndarray:\n    keys = random.split(key, n_samples)\n    return jax.vmap(partial(_sample_beta_binomial, n=n, alpha=alpha, beta=beta))(keys)\n\n\ndef plot_compare(key, ax: plt.Axes, n: int, p: float, w: float, n_samples: int = 1_000_000, n_bins: int | None = None) -> None:\n    variance = variance_correlated_binomial(n=n, p=p, w=w)\n    alpha, beta = find_alpha_beta(n=n, p=p, variance=variance)\n\n    key1, key2 = random.split(key)\n    sample_corr = sample_correlated_binomial(key1, n=n, p=p, w=w, n_samples=n_samples)\n    sample_betabin = sample_beta_binomial(key2, n=n, alpha=alpha, beta=beta, n_samples=n_samples)\n\n    if n_bins is None:\n        bins = jnp.arange(-0.5, n + 1.5, 1)\n    else:\n        bins = jnp.linspace(-0.1, n + 0.1, n_bins)\n\n    ax.hist(\n        sample_corr, bins=bins, density=True, rasterized=True,\n        color=\"yellow\",\n        label=\"Markov chain\",\n        histtype=\"step\",\n    )\n    ax.hist(\n        sample_betabin, bins=bins, density=True, rasterized=True,\n        color=\"orange\",\n        label=\"Beta-binomial\",\n        histtype=\"step\",\n        linestyle=\"--\"\n    )\n    ax.spines[[\"top\", \"right\"]].set_visible(False)\n    ax.set_xlabel(\"Number of heads\")\n    ax.set_ylabel(\"Probability\")\n\n\nfig, _axs = plt.subplots(2, 2, dpi=250)\naxs = _axs.ravel()\n\nkey, *keys = random.split(key, 1 + len(axs))\n\nparams = [\n    # (n, p, w, n_bins)\n    (10, 0.5, 0.9, None),\n    (10, 0.3, 0.2, None),\n    (100, 0.7, 0.98, 41),\n    (100, 0.3, 0.6, 41),\n]\nassert len(params) == len(axs)\n\nfor key, ax, (n, p, w, n_bins) in zip(keys, axs, params):\n    plot_compare(\n        key=key,\n        ax=ax,\n        n=n,\n        p=p,\n        w=w,\n        n_samples=1_000_000,\n        n_bins=n_bins,\n)\naxs[0].legend(frameon=False)\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](almost-binomial-markov-chain_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "almost-binomial-markov-chain_files"
    ],
    "filters": [],
    "includes": {}
  }
}
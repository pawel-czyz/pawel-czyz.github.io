---
title: "The no free lunch theorem for scientific research"
description: "A perfect paper should have novel methodology, solve an important problem, and be correct (what should go without saying). In practice, the no free lunch theorem says that at most two of these are possible."
author: "Paweł Czyż"
date: "9/28/2023"
---

Yesterday David and I went for pizza after work.
As typical for our conversations, we spent quite some time discussing applied statistics and machine learning, and reached our usual conclusion that logistic regression is a wonderful model in *so many* problems.

However, finding logistic regression or other "simple" methods in research papers can be quite hard, as we tend to look for methodological novelty.
As [Kristin Lennox nicely summarized](https://youtu.be/be2wuOaglFY?feature=shared&t=565), *"you don't get a lot of points for doing really good statistics on really important problems, if these statistics were invented in 1950s"*. (In particular, [Cynthia Rudin investigated](https://youtu.be/XZUZ87wfq70?feature=shared) how much applied research goes into the most presitigious machine learning conferences).

This is one of the reasons for the phenomenon which everybody in the field knows too well: from time to time you take a paper claiming state-of-the-art performance ("They are 0.02% better on CIFAR-10 than others! Let's apply it to my problem"), and then finding out that the method requires heavy hyperparameter tuning and hours of playing with the brittleness that makes the method impossible to use in practice. And, what's even worse, the performance isn't that different from a simple baseline.

Similarly, there are [voices](https://darrendahly.github.io/post/cluster/) from [many](https://elevanth.org/blog/2021/06/15/regression-fire-and-dangerous-things-1-3/) [statisticians](https://www.fharrell.com/post/badb/) raising the issue that several of the grandiose results, which often involve solving important problems with the state-of-the-art methodology, may be simply invalid.

To summarize, a perfect paper should use **novel methodology**, aim at solving **an important problem**, and **be correct** (which should go without saying).
The no free lunch of scientific research says that *you can pick two out of three, at most*.

This is of course not universal – there exist great [papers](https://doi.org/10.1038/s41586-021-03819-2), rare [gems](https://arxiv.org/abs/1312.6114), wonderful to read and to apply their methodology in practice.
Plus, I don't want to dichotomise here: methodological novelty, problem importance and correctness have many facets and subtleties, and may also be hard to assess upfront.

So when I'm planning my next research project, I'm going to be realistic: should I develop a novel cool method (illustrated on a toy problem), try to solve an important problem using well-known tools, or (perhap correctly) tackle a simple problem with a well-known tool?
